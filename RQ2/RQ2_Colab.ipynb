{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RQ2: Explanation Generation for Toxic Completions\n",
        "\n",
        "This notebook generates attention-based explanations for toxic model completions using `inseq`.\n",
        "\n",
        "**Features:**\n",
        "- Automatic checkpointing (resume after session timeout)\n",
        "- 8-bit quantization for memory efficiency\n",
        "- Support for Gemma and Mistral models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected. Please enable GPU in Runtime > Change runtime type > GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers bitsandbytes inseq accelerate huggingface_hub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Hugging Face Authentication\n",
        "\n",
        "Required for accessing gated models (e.g., Gemma). Get your token from https://huggingface.co/settings/tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Run this cell and enter your Hugging Face token when prompted\n",
        "# Or set it directly: token = \"your_token_here\"\n",
        "login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Upload Data Files\n",
        "\n",
        "Upload the following files from your RQ1 folder:\n",
        "- `toxic.jsonl`\n",
        "- `completions_scores_gemma.jsonl`\n",
        "- `completions_scores_mistral.jsonl`\n",
        "\n",
        "**Alternative:** Mount Google Drive and copy files from there\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory structure\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.makedirs(\"RQ1\", exist_ok=True)\n",
        "print(\"Created RQ1 directory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Use Colab's file upload widget\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload toxic.jsonl:\")\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if 'toxic.jsonl' in filename:\n",
        "        os.rename(filename, f\"RQ1/{filename}\" if not filename.startswith('RQ1/') else filename)\n",
        "        print(f\"Saved: {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload completion scores files\n",
        "print(\"Upload completions_scores_*.jsonl files:\")\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if 'completions_scores' in filename:\n",
        "        os.rename(filename, f\"RQ1/{filename}\" if not filename.startswith('RQ1/') else filename)\n",
        "        print(f\"Saved: {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify files are present\n",
        "required_files = [\n",
        "    \"RQ1/toxic.jsonl\",\n",
        "    \"RQ1/completions_scores_gemma.jsonl\",\n",
        "    \"RQ1/completions_scores_mistral.jsonl\"\n",
        "]\n",
        "\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        size = os.path.getsize(file) / 1024  # KB\n",
        "        print(f\"✓ {file} ({size:.1f} KB)\")\n",
        "    else:\n",
        "        print(f\"✗ {file} - MISSING\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative: Mount Google Drive\n",
        "\n",
        "If your files are in Google Drive, use this instead:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# \n",
        "# # Copy files from Drive to working directory\n",
        "# import shutil\n",
        "# shutil.copytree('/content/drive/MyDrive/path/to/RQ1', 'RQ1', dirs_exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run Explanation Generation\n",
        "\n",
        "This will process toxic completions and generate attention-based attributions. The script automatically saves checkpoints every 50 items, so you can resume if the session times out.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import inseq\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "TOXICITY_THRESHOLD = 0.7\n",
        "MODEL_CONFIGS = {\n",
        "    \"gemma\": \"google/gemma-7b\",\n",
        "    # \"llama3\": \"meta-llama/Meta-Llama-3-8B\",  # Commented out due to compatibility issues\n",
        "    \"mistral\": \"mistralai/Mistral-7B-v0.1\"\n",
        "}\n",
        "CHECKPOINT_INTERVAL = 50\n",
        "USE_8BIT = True\n",
        "\n",
        "def load_prompts(prompts_file):\n",
        "    prompts = []\n",
        "    with open(prompts_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                prompts.append(json.loads(line)['prompt']['text'])\n",
        "    return prompts\n",
        "\n",
        "def load_completions_with_scores(scores_file):\n",
        "    completions, scores = [], []\n",
        "    with open(scores_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                record = json.loads(line)\n",
        "                completions.append(record['completion'])\n",
        "                scores.append(record['score'])\n",
        "    return completions, scores\n",
        "\n",
        "def filter_toxic_outputs(prompts, completions, scores, threshold):\n",
        "    toxic_prompts, toxic_completions, toxic_scores = [], [], []\n",
        "    for prompt, completion, score in zip(prompts, completions, scores):\n",
        "        if score >= threshold:\n",
        "            toxic_prompts.append(prompt)\n",
        "            toxic_completions.append(completion)\n",
        "            toxic_scores.append(score)\n",
        "    return toxic_prompts, toxic_completions, toxic_scores\n",
        "\n",
        "def load_checkpoint(checkpoint_file):\n",
        "    if os.path.exists(checkpoint_file):\n",
        "        print(f\"Loading checkpoint from {checkpoint_file}\")\n",
        "        with open(checkpoint_file, 'r', encoding='utf-8') as f:\n",
        "            checkpoint = json.load(f)\n",
        "        return set(checkpoint.get('processed_indices', [])), checkpoint.get('results', [])\n",
        "    return set(), []\n",
        "\n",
        "def save_checkpoint(checkpoint_file, processed_indices, results):\n",
        "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump({\n",
        "            'processed_indices': list(processed_indices),\n",
        "            'results': results\n",
        "        }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "def compute_explanations(model_name, prompts, completions, output_file=None):\n",
        "    print(f\"Loading model: {model_name}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB)\")\n",
        "    \n",
        "    checkpoint_file = output_file.replace('.json', '_checkpoint.json') if output_file else None\n",
        "    processed_indices, results = load_checkpoint(checkpoint_file) if checkpoint_file else (set(), [])\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if USE_8BIT and torch.cuda.is_available():\n",
        "        from transformers import BitsAndBytesConfig\n",
        "        print(\"Using 8-bit quantization\")\n",
        "        model = inseq.load_model(\n",
        "            model_name, \n",
        "            \"attention\",\n",
        "            model_kwargs={\n",
        "                \"quantization_config\": BitsAndBytesConfig(load_in_8bit=True),\n",
        "                \"device_map\": \"auto\",\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        model = inseq.load_model(model_name, \"attention\")\n",
        "    \n",
        "    print(f\"Computing attributions for {len(prompts)} toxic outputs using attention...\")\n",
        "    print(f\"Resuming from checkpoint: {len(processed_indices)} items already processed\")\n",
        "    \n",
        "    for i, (prompt, completion) in enumerate(zip(prompts, completions)):\n",
        "        if i in processed_indices:\n",
        "            continue\n",
        "            \n",
        "        if (i + 1) % 10 == 0:\n",
        "            print(f\"Processing {i + 1}/{len(prompts)}\")\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        \n",
        "        try:\n",
        "            full_text = prompt + completion\n",
        "            \n",
        "            # Tokenize to get tokens and identify prompt/completion boundary\n",
        "            tokenizer = model.tokenizer if hasattr(model, 'tokenizer') else model.model.tokenizer\n",
        "            \n",
        "            # Tokenize full sequence\n",
        "            full_tokenized = tokenizer(full_text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "            tokens = tokenizer.convert_ids_to_tokens(full_tokenized['input_ids'][0])\n",
        "            tokens = [t.replace('▁', ' ') if '▁' in t else t for t in tokens]  # Clean SentencePiece tokens\n",
        "            \n",
        "            # Find prompt boundary by tokenizing prompt separately and matching\n",
        "            prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
        "            prompt_token_ids = prompt_tokenized['input_ids'][0].tolist()\n",
        "            full_token_ids = full_tokenized['input_ids'][0].tolist()\n",
        "            \n",
        "            # Find where prompt tokens end in the full sequence\n",
        "            prompt_end_idx = len(prompt_token_ids)\n",
        "            # Account for potential differences in special tokens\n",
        "            if prompt_token_ids == full_token_ids[:len(prompt_token_ids)]:\n",
        "                prompt_end_idx = len(prompt_token_ids)\n",
        "            else:\n",
        "                # Fallback: use prompt length as approximation\n",
        "                prompt_end_idx = len([t for t in tokens if t and not t.startswith('<')])  # Rough estimate\n",
        "            \n",
        "            out = model.attribute(full_text)\n",
        "            \n",
        "            # Extract attributions using Inseq's default aggregation (mean across heads, then layers)\n",
        "            token_attrs = []\n",
        "            if hasattr(out, 'sequence_attributions') and len(out.sequence_attributions) > 0:\n",
        "                seq_attr = out.sequence_attributions[0]\n",
        "                \n",
        "                # Get attributions and apply Inseq's aggregation strategy\n",
        "                attrs = seq_attr.target_attributions if hasattr(seq_attr, 'target_attributions') and seq_attr.target_attributions is not None else None\n",
        "                if attrs is None and hasattr(seq_attr, 'source_attributions') and seq_attr.source_attributions is not None:\n",
        "                    attrs = seq_attr.source_attributions\n",
        "                \n",
        "                if attrs is not None:\n",
        "                    # Get aggregation strategy (default for attention: [\"mean\", \"mean\"])\n",
        "                    agg_functions = seq_attr._aggregator if hasattr(seq_attr, '_aggregator') and isinstance(seq_attr._aggregator, list) else [\"mean\", \"mean\"]\n",
        "                    \n",
        "                    # Convert to numpy\n",
        "                    attrs_np = np.array(attrs.cpu() if hasattr(attrs, 'cpu') else attrs)\n",
        "                    \n",
        "                    if len(attrs_np.shape) > 1 and attrs_np.size > 0:\n",
        "                        # Apply aggregation functions from right to left (innermost dimensions first)\n",
        "                        for agg_func in agg_functions:\n",
        "                            if len(attrs_np.shape) > 1 and attrs_np.size > 0:\n",
        "                                axis_size = attrs_np.shape[-1]\n",
        "                                if axis_size > 0:\n",
        "                                    with np.errstate(invalid='ignore'):\n",
        "                                        if agg_func == \"mean\":\n",
        "                                            attrs_np = np.nanmean(attrs_np, axis=-1)\n",
        "                                        elif agg_func == \"sum\":\n",
        "                                            attrs_np = np.nansum(attrs_np, axis=-1)\n",
        "                                        elif agg_func == \"max\":\n",
        "                                            attrs_np = np.nanmax(attrs_np, axis=-1)\n",
        "                                        else:\n",
        "                                            attrs_np = np.nanmean(attrs_np, axis=-1)  # Default to mean\n",
        "                                else:\n",
        "                                    # Empty axis, skip aggregation\n",
        "                                    break\n",
        "                    \n",
        "                    # If still 2D [seq_len, gen_steps], take mean across generation steps\n",
        "                    if len(attrs_np.shape) == 2 and attrs_np.size > 0 and attrs_np.shape[-1] > 0:\n",
        "                        with np.errstate(invalid='ignore'):\n",
        "                            attrs_np = np.nanmean(attrs_np, axis=-1)\n",
        "                    \n",
        "                    # Flatten to 1D\n",
        "                    if attrs_np.size > 0:\n",
        "                        token_attrs = attrs_np.flatten().tolist()\n",
        "                    else:\n",
        "                        token_attrs = [0.0] * len(tokens)\n",
        "                else:\n",
        "                    token_attrs = [0.0] * len(tokens)\n",
        "            else:\n",
        "                token_attrs = [0.0] * len(tokens)\n",
        "            \n",
        "            # Replace NaN with 0 and ensure proper length\n",
        "            token_attrs = [0.0 if (isinstance(x, float) and (x != x or x == float('inf'))) else float(x) for x in token_attrs]\n",
        "            \n",
        "            # Ensure attributions match token length\n",
        "            if len(token_attrs) > len(tokens):\n",
        "                token_attrs = token_attrs[:len(tokens)]\n",
        "            elif len(token_attrs) < len(tokens):\n",
        "                token_attrs.extend([0.0] * (len(tokens) - len(token_attrs)))\n",
        "            \n",
        "            # Verify alignment\n",
        "            if len(tokens) != len(token_attrs):\n",
        "                print(f\"Warning: Token/attribution length mismatch: {len(tokens)} tokens vs {len(token_attrs)} attributions\")\n",
        "            \n",
        "            # Extract prompt and completion tokens/attributions for easier analysis\n",
        "            prompt_tokens = tokens[:prompt_end_idx] if prompt_end_idx <= len(tokens) else tokens\n",
        "            completion_tokens = tokens[prompt_end_idx:] if prompt_end_idx < len(tokens) else []\n",
        "            prompt_attributions = token_attrs[:prompt_end_idx] if prompt_end_idx <= len(token_attrs) else token_attrs\n",
        "            completion_attributions = token_attrs[prompt_end_idx:] if prompt_end_idx < len(token_attrs) else []\n",
        "            \n",
        "            results.append({\n",
        "                \"prompt_tokens\": prompt_tokens,\n",
        "                \"completion_tokens\": completion_tokens,\n",
        "                \"prompt_attributions\": prompt_attributions,\n",
        "                \"completion_attributions\": completion_attributions\n",
        "            })\n",
        "            processed_indices.add(i)\n",
        "            \n",
        "            if checkpoint_file and (i + 1) % CHECKPOINT_INTERVAL == 0:\n",
        "                print(f\"Saving checkpoint at item {i + 1}...\")\n",
        "                save_checkpoint(checkpoint_file, processed_indices, results)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing item {i + 1}: {e}\")\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                gc.collect()\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            results.append({\n",
        "                \"prompt\": prompt,\n",
        "                \"completion\": completion,\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "            processed_indices.add(i)\n",
        "            \n",
        "            if checkpoint_file:\n",
        "                save_checkpoint(checkpoint_file, processed_indices, results)\n",
        "    \n",
        "    if output_file:\n",
        "        print(f\"Saving final results to {output_file}\")\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        if checkpoint_file and os.path.exists(checkpoint_file):\n",
        "            os.remove(checkpoint_file)\n",
        "            print(\"Checkpoint file removed after successful completion\")\n",
        "\n",
        "print(\"Functions loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the main analysis\n",
        "prompts_file = Path(\"RQ1/toxic.jsonl\")\n",
        "\n",
        "for model_key, model_name in MODEL_CONFIGS.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {model_key.upper()} model\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    scores_file = Path(f\"RQ1/completions_scores_{model_key}.jsonl\")\n",
        "    if not scores_file.exists():\n",
        "        print(f\"Warning: {scores_file} not found, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    print(\"Loading prompts and completions...\")\n",
        "    prompts = load_prompts(prompts_file)\n",
        "    completions, scores = load_completions_with_scores(scores_file)\n",
        "    \n",
        "    print(f\"Filtering outputs with toxicity >= {TOXICITY_THRESHOLD}...\")\n",
        "    toxic_prompts, toxic_completions, toxic_scores = filter_toxic_outputs(\n",
        "        prompts, completions, scores, TOXICITY_THRESHOLD\n",
        "    )\n",
        "    print(f\"Found {len(toxic_prompts)} toxic outputs (out of {len(prompts)} total)\")\n",
        "    \n",
        "    if len(toxic_prompts) == 0:\n",
        "        print(\"No toxic outputs found, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    output_file = f\"explanations_{model_key}.json\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    compute_explanations(model_name, toxic_prompts, toxic_completions, output_file)\n",
        "    print(f\"Completed processing {model_key} model\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download Results\n",
        "\n",
        "After completion, download the generated explanation files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List generated files\n",
        "import glob\n",
        "\n",
        "result_files = glob.glob(\"explanations_*.json\")\n",
        "print(\"Generated files:\")\n",
        "for file in result_files:\n",
        "    size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
        "    print(f\"  {file} ({size:.2f} MB)\")\n",
        "\n",
        "# Download files\n",
        "for file in result_files:\n",
        "    files.download(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resuming After Session Timeout\n",
        "\n",
        "If your Colab session times out:\n",
        "1. Re-run all cells up to \"Run Explanation Generation\"\n",
        "2. Re-run the main analysis cell - it will automatically detect and resume from checkpoints\n",
        "3. The checkpoint files (`*_checkpoint.json`) are automatically cleaned up after successful completion\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
